{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3169,"status":"ok","timestamp":1648571321407,"user":{"displayName":"Ashwath VA","userId":"09478984877506505652"},"user_tz":-330},"id":"TCmBmyreQXFJ","outputId":"c5f67dc6-15ee-4a42-c214-a483e0a86316"},"outputs":[],"source":["!pip install mnist"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1648571321409,"user":{"displayName":"Ashwath VA","userId":"09478984877506505652"},"user_tz":-330},"id":"Ww_KK4ojPgro"},"outputs":[],"source":["import numpy as np\n","import mnist"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1648571321411,"user":{"displayName":"Ashwath VA","userId":"09478984877506505652"},"user_tz":-330},"id":"oy3KunycPA2R"},"outputs":[],"source":["class Conv3x3:\n","  def __init__(self, num_filters):\n","    self.num_filters = num_filters\n","    self.filters = np.random.randn(num_filters, 3, 3) / 9\n","\n","  def iterate_regions(self, image):\n","    h, w = image.shape\n","\n","    for i in range(h-2):\n","      for j in range(w-2):\n","        im_region = image[i: (i+3), j: (j+3)]\n","        yield im_region, i, j\n","\n","  def forward(self, input):\n","    self.last_input = input\n","\n","    h, w = input.shape\n","    output = np.zeros((h-2, w-2, self.num_filters))\n","    for im_region, i, j in self.iterate_regions(input):\n","      output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n","\n","    return output\n","\n","  def backprop(self, d_L_d_out, learn_rate):\n","\n","    d_L_d_filters = np.zeros(self.filters.shape)\n","\n","    for im_region, i, j in self.iterate_regions(self.last_input):\n","      for f in range(self.num_filters):\n","        d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region\n","\n","    self.filters -= learn_rate * d_L_d_filters\n","\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1648571321412,"user":{"displayName":"Ashwath VA","userId":"09478984877506505652"},"user_tz":-330},"id":"h8-XAoGQQGM3"},"outputs":[],"source":["class MaxPool2:\n","  def iterate_regions(self, image):\n","    h, w, _ = image.shape\n","    new_h = h//2\n","    new_w = w//2\n","\n","    for i in range(new_h):\n","      for j in range(new_w):\n","        im_region = image[(i*2):(i*2 + 2), (j*2):(j*2 + 2)]\n","        yield im_region, i, j\n","  \n","  def forward(self, input):\n","\n","    self.last_input = input\n","\n","    h, w, num_filters = input.shape\n","    output = np.zeros((h//2, w//2, num_filters))\n","\n","    for im_region, i, j in self.iterate_regions(input):\n","      output[i, j] = np.amax(im_region, axis=(0,1))\n","    \n","    return output\n","\n","  def backprop(self, d_L_d_out):\n","    d_L_d_input = np.zeros(self.last_input.shape)\n","\n","    for im_region, i, j in self.iterate_regions(self.last_input):\n","      h, w, f = im_region.shape\n","      amax = np.amax(im_region, axis=(0, 1))\n","\n","      for i2 in range(h):\n","        for j2 in range(w):\n","          for f2 in range(f):\n","            if im_region[i2, j2, f2] == amax[f2]:\n","              d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]\n","\n","    return d_L_d_input"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1648571321977,"user":{"displayName":"Ashwath VA","userId":"09478984877506505652"},"user_tz":-330},"id":"IsAKFsCxdfRB"},"outputs":[],"source":["class Softmax:\n","  def __init__(self, input_len, nodes):\n","    self.weights = np.random.randn(input_len, nodes) / input_len\n","    self.biases = np.zeros(nodes)\n","\n","  def forward(self, input):\n","    self.last_input_shape = input.shape\n","\n","    input = input.flatten()\n","    self.last_input = input\n","\n","    input_len, nodes = self.weights.shape\n","\n","    totals = np.dot(input, self.weights) + self.biases\n","    self.last_totals = totals\n","\n","    exp = np.exp(totals)\n","    return exp/np.sum(exp, axis=0)\n","\n","  def backprop(self, d_L_d_out, learn_rate):\n","    '''\n","    Performs a backward pass of the softmax layer.\n","    Returns the loss gradient for this layer's inputs.\n","    - d_L_d_out is the loss gradient for this layer's outputs.\n","    - learn_rate is a float.\n","    '''\n","    # We know only 1 element of d_L_d_out will be nonzero\n","    for i, gradient in enumerate(d_L_d_out):\n","      if gradient == 0:\n","        continue\n","\n","      # e^totals\n","      t_exp = np.exp(self.last_totals)\n","\n","      # Sum of all e^totals\n","      S = np.sum(t_exp)\n","\n","      # Gradients of out[i] against totals\n","      d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n","      d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n","\n","      # Gradients of totals against weights/biases/input\n","      d_t_d_w = self.last_input\n","      d_t_d_b = 1\n","      d_t_d_inputs = self.weights\n","\n","      # Gradients of loss against totals\n","      d_L_d_t = gradient * d_out_d_t\n","\n","      # Gradients of loss against weights/biases/input\n","      d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n","      d_L_d_b = d_L_d_t * d_t_d_b\n","      d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n","\n","      # Update weights / biases\n","      self.weights -= learn_rate * d_L_d_w\n","      self.biases -= learn_rate * d_L_d_b\n","\n","      return d_L_d_inputs.reshape(self.last_input_shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211044,"status":"ok","timestamp":1648571533005,"user":{"displayName":"Ashwath VA","userId":"09478984877506505652"},"user_tz":-330},"id":"S51CiXrxdWhK","outputId":"9082ba9d-20a1-4020-eba2-dadaa3c33296"},"outputs":[],"source":["train_images = mnist.train_images()[:1000]\n","train_labels = mnist.train_labels()[:1000]\n","test_images = mnist.test_images()[:1000]\n","test_labels = mnist.test_labels()[:1000]\n","\n","conv = Conv3x3(8)                  # 28x28x1 -> 26x26x8\n","pool = MaxPool2()                  # 26x26x8 -> 13x13x8\n","softmax = Softmax(13 * 13 * 8, 10) # 13x13x8 -> 10\n","\n","def forward(image, label):\n","  '''\n","  Completes a forward pass of the CNN and calculates the accuracy and\n","  cross-entropy loss.\n","  - image is a 2d numpy array\n","  - label is a digit\n","  '''\n","  # We transform the image from [0, 255] to [-0.5, 0.5] to make it easier\n","  # to work with. This is standard practice.\n","  out = conv.forward((image / 255) - 0.5)\n","  out = pool.forward(out)\n","  out = softmax.forward(out)\n","\n","  # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n","  loss = -np.log(out[label])\n","  acc = 1 if np.argmax(out) == label else 0\n","\n","  return out, loss, acc\n","\n","def train(im, label, lr=.005):\n","  '''\n","  Completes a full training step on the given image and label.\n","  Returns the cross-entropy loss and accuracy.\n","  - image is a 2d numpy array\n","  - label is a digit\n","  - lr is the learning rate\n","  '''\n","  # Forward\n","  out, loss, acc = forward(im, label)\n","\n","  # Calculate initial gradient\n","  gradient = np.zeros(10)\n","  gradient[label] = -1 / out[label]\n","\n","  # Backprop\n","  gradient = softmax.backprop(gradient, lr)\n","  gradient = pool.backprop(gradient)\n","  gradient = conv.backprop(gradient, lr)\n","\n","  return loss, acc\n","\n","print('MNIST CNN initialized!')\n","\n","# Train the CNN for 3 epochs\n","for epoch in range(3):\n","  print('--- Epoch %d ---' % (epoch + 1))\n","\n","  # Shuffle the training data\n","  permutation = np.random.permutation(len(train_images))\n","  train_images = train_images[permutation]\n","  train_labels = train_labels[permutation]\n","\n","  # Train!\n","  loss = 0\n","  num_correct = 0\n","  for i, (im, label) in enumerate(zip(train_images, train_labels)):\n","    if i > 0 and i % 100 == 99:\n","      print(\n","        '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\n","        (i + 1, loss / 100, num_correct)\n","      )\n","      loss = 0\n","      num_correct = 0\n","\n","    l, acc = train(im, label)\n","    loss += l\n","    num_correct += acc\n","\n","# Test the CNN\n","print('\\n--- Testing the CNN ---')\n","loss = 0\n","num_correct = 0\n","for im, label in zip(test_images, test_labels):\n","  _, l, acc = forward(im, label)\n","  loss += l\n","  num_correct += acc\n","\n","num_tests = len(test_images)\n","print('Test Loss:', loss / num_tests)\n","print('Test Accuracy:', num_correct / num_tests)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPkVRIHBbeYfqHhPiftSjpO","name":"CNN_MNIST.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
